{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvilwOzl9kLQ",
        "outputId": "29ba0d2d-17a9-4acc-d0f5-10e84d8874f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"This is an example document that we will use to demonstrate document preprocessing.\""
      ],
      "metadata": {
        "id": "V7cnrnCo-aqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(document)"
      ],
      "metadata": {
        "id": "th6vuGUN-cjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovph1B2K-_Xb",
        "outputId": "0aff93f1-547d-42d6-f924-71ba1f2c8885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'an',\n",
              " 'example',\n",
              " 'document',\n",
              " 'that',\n",
              " 'we',\n",
              " 'will',\n",
              " 'use',\n",
              " 'to',\n",
              " 'demonstrate',\n",
              " 'document',\n",
              " 'preprocessing',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS tagging\n",
        "pos_tags = pos_tag(tokens)"
      ],
      "metadata": {
        "id": "2svJsqYq_Hme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaKome6W_YRT",
        "outputId": "87027cbd-1b7d-4993-b5af-b4c9fd8c3dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('an', 'DT'),\n",
              " ('example', 'NN'),\n",
              " ('document', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('we', 'PRP'),\n",
              " ('will', 'MD'),\n",
              " ('use', 'VB'),\n",
              " ('to', 'TO'),\n",
              " ('demonstrate', 'VB'),\n",
              " ('document', 'NN'),\n",
              " ('preprocessing', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwords removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if not word.lower() in stop_words]"
      ],
      "metadata": {
        "id": "OSBJqCO4_bee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVb-wGgw_x-9",
        "outputId": "0488ca65-006a-457c-a726-21cddac54777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['example', 'document', 'use', 'demonstrate', 'document', 'preprocessing', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "ps = PorterStemmer()\n",
        "stemmed_tokens = [ps.stem(word) for word in filtered_tokens]"
      ],
      "metadata": {
        "id": "RDuosgiV_8x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4pVy3SQAJqw",
        "outputId": "b761ae6e-52bc-4f9d-c53e-89e71bc7fd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['exampl', 'document', 'use', 'demonstr', 'document', 'preprocess', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "wnl = WordNetLemmatizer()\n",
        "lemmatized_tokens = [wnl.lemmatize(word) for word in filtered_tokens]"
      ],
      "metadata": {
        "id": "Il-yKwGoAQka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZmwSIJ4ATPa",
        "outputId": "216d3413-cc0a-461a-f9f2-3a561dca122a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['example', 'document', 'use', 'demonstrate', 'document', 'preprocessing', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd part tf-idf"
      ],
      "metadata": {
        "id": "Dxv_NLY0Adqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "dhlkfTPvAnXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "'The quick brown fox jumps over the lazy dog',\n",
        "'The brown fox is quick',\n",
        "'The lazy dog is sleeping'\n",
        "]"
      ],
      "metadata": {
        "id": "KFcywLisArmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_docs = [doc.lower().split() for doc in corpus]"
      ],
      "metadata": {
        "id": "K5npUoy2Aupt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the term frequency for each document\n",
        "tf_docs = [Counter(tokens) for tokens in tokenized_docs]"
      ],
      "metadata": {
        "id": "laTeH4A8Av7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the inverse document frequency for each term\n",
        "n_docs = len(corpus)\n",
        "idf = {}\n",
        "for tokens in tokenized_docs:\n",
        "  for token in set(tokens):\n",
        "    idf[token] = idf.get(token, 0) + 1\n",
        "for token in idf:\n",
        "  idf[token] = math.log(n_docs / idf[token])\n"
      ],
      "metadata": {
        "id": "tTNNVoaxBI1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the TF-IDF weights for each document\n",
        "tfidf_docs = []\n",
        "for tf_doc in tf_docs:\n",
        "  tfidf_doc = {}\n",
        "  for token, freq in tf_doc.items():\n",
        "    tfidf_doc[token] = freq * idf[token]\n",
        "  tfidf_docs.append(tfidf_doc)"
      ],
      "metadata": {
        "id": "zI__O3UTBZzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the resulting TF-IDF representation for each document\n",
        "for i, tfidf_doc in enumerate(tfidf_docs):\n",
        "  print(f\"Document {i+1}: {tfidf_doc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcQU3Yg0BmqO",
        "outputId": "c539c74c-cbd0-4511-dbf4-1af2ab29d488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1: {'the': 0.0, 'quick': 0.4054651081081644, 'brown': 0.4054651081081644, 'fox': 0.4054651081081644, 'jumps': 1.0986122886681098, 'over': 1.0986122886681098, 'lazy': 0.4054651081081644, 'dog': 0.4054651081081644}\n",
            "Document 2: {'the': 0.0, 'brown': 0.4054651081081644, 'fox': 0.4054651081081644, 'is': 0.4054651081081644, 'quick': 0.4054651081081644}\n",
            "Document 3: {'the': 0.0, 'lazy': 0.4054651081081644, 'dog': 0.4054651081081644, 'is': 0.4054651081081644, 'sleeping': 1.0986122886681098}\n"
          ]
        }
      ]
    }
  ]
}